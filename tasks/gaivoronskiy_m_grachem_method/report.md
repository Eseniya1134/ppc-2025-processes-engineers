# Построение выпуклой оболочки – проход Грэхема

- **Студент:** Гайворонский Максим Витальевич, группа 3823Б1ПР1
- **Технология:** SEQ | MPI
- **Вариант:** 24
- **Преподаватель:** Сысоев Александр Владимирович, лектор, доцент кафедры высокопроизводительных вычислений и системногo программирования

## 1. Введение

Выпуклая оболочка - это наименьший выпуклый многоугольник, содержащий все заданные точки на плоскости. Алгоритм Грэхема (Graham Scan) является одним из классических методов построения выпуклой оболочки с оптимальной временной сложностью O(n log n).

**Цель работы:** Реализовать алгоритм Грэхема двумя способами (последовательный и параллельный) и провести анализ их производительности.

**Задачи:**
1. Реализовать последовательную версию алгоритма Грэхема
2. Реализовать параллельную версию с использованием технологии MPI
3. Провести сравнительный анализ производительности и эффективности обеих реализаций

## 2. Постановка задачи

**Задача:** Построить выпуклую оболочку для множества точек на плоскости.

**Входные данные:**
- Вектор точек `std::vector<Point>`, где `Point` - структура с координатами (x, y)

**Выходные данные:**
- Вектор точек `std::vector<Point>`, образующих выпуклую оболочку в порядке обхода против часовой стрелки

**Ограничения:**
- Количество точек >= 3

## 3. Описание алгоритма (последовательного)

Алгоритм Грэхема работает следующим образом:

1. **Поиск опорной точки:** Находим точку с минимальной y-координатой (при равенстве - с минимальной x)
2. **Сортировка:** Сортируем все остальные точки по полярному углу относительно опорной точки
3. **Построение оболочки:** Используя стек, строим выпуклую оболочку:
   - Для каждой новой точки проверяем ориентацию с двумя последними точками на стеке
   - Если образуется правый поворот, удаляем последнюю точку из стека
   - Добавляем текущую точку в стек
4. Точки в стеке образуют выпуклую оболочку

**Временная сложность:** O(n log n), где n - количество точек (доминирует сортировка)
**Пространственная сложность:** O(n)

## 4. Схема распараллеливания (MPI)

Параллельная версия использует подход "разделяй и властвуй":

**Алгоритм параллельного вычисления:**

1. **Распределение данных (PreProcessing):**
   - Процесс 0 преобразует точки в плоский массив (x₁, y₁, x₂, y₂, ...)
   - Данные распределяются между процессами через `MPI_Scatterv`
   - Каждый процесс получает примерно N/P точек

2. **Локальные вычисления (Run):**
   - Каждый процесс строит локальную выпуклую оболочку для своего подмножества точек
   - Используется тот же алгоритм Грэхема

3. **Сбор результатов (Run):**
   - Размеры локальных оболочек собираются через `MPI_Gather`
   - Локальные оболочки собираются на процессе 0 через `MPI_Gatherv`

4. **Финальное объединение (Run):**
   - Процесс 0 строит финальную выпуклую оболочку из всех точек локальных оболочек

**Коммуникация:**
- `MPI_Bcast` - рассылка количества точек
- `MPI_Scatterv` - распределение точек между процессами
- `MPI_Gather` - сбор размеров локальных оболочек
- `MPI_Gatherv` - сбор локальных оболочек

**Схема распределения:**
```
Процесс 0: [точки 0...k₀] -> локальная оболочка₀  ─┐
Процесс 1: [точки k₀...k₁] -> локальная оболочка₁  ├─> MPI_Gatherv -> Финальная оболочка
...                                                  │
Процесс P-1: [точки kₚ₋₂...N] -> локальная оболочкаₚ₋₁ ┘
```

## 5. Детали реализации

### Структура кода

**Файлы:**
- `common/include/common.hpp` - общие типы данных (Point, InType, OutType)
- `seq/include/ops_seq.hpp`, `seq/src/ops_seq.cpp` - последовательная версия
- `mpi/include/ops_mpi.hpp`, `mpi/src/ops_mpi.cpp` - параллельная версия
- `tests/functional/main.cpp` - функциональные тесты
- `tests/performance/main.cpp` - тесты производительности

**Классы:**
- `GaivoronskiyMGrahamScanSEQ` - последовательная реализация
- `GaivoronskiyMGrahamScanMPI` - параллельная реализация

**Методы:**
- `ValidationImpl()` - проверка входных данных (количество точек >= 3)
- `PreProcessingImpl()` - подготовка данных (для MPI - распределение точек)
- `RunImpl()` - основной алгоритм построения выпуклой оболочки
- `PostProcessingImpl()` - проверка результата

**Ключевые функции:**
- `orientation()` - определение ориентации трех точек (0 - коллинеарны, 1 - по часовой, 2 - против часовой)
- `distSquare()` - вычисление квадрата расстояния между точками
- `compare()` - функция сравнения для сортировки по полярному углу
- `grahamScan()` (MPI) - статический метод для построения оболочки

### Граничные случаи

- **N = 3:** Все три точки образуют выпуклую оболочку (треугольник)
- **N < P:** Некоторые процессы получают пустые блоки данных, они возвращают пустые локальные оболочки
- **Коллинеарные точки:** Алгоритм корректно обрабатывает точки, лежащие на одной прямой
- **Дублирующиеся точки:** При сортировке оставляется самая дальняя от опорной точки

## 6. Экспериментальная среда

### 6.1. Аппаратное обеспечение

| Параметр | Значение |
|----------|----------|
| CPU | AMD Ryzen 7 5800H @ 3.20GHz |
| Ядра/Потоки | 8 ядер / 16 потоков |
| RAM | 16 GB DDR4 |

### 6.2. Программное обеспечение

| Параметр | Значение |
|----------|----------|
| ОС | macOS 14.5 |
| MPI | OpenMPI 5.0 |
| Компилятор | Apple Clang 16.0 |
| Сборка | Release |

### 6.3. Тестовые данные

**Функциональные тесты:**

Используют заранее подготовленные наборы точек:
1. Треугольник (3 точки)
2. Квадрат (4 точки)
3. Квадрат с внутренними точками (7 точек)
4. Окружность (8 точек)
5. Сложный набор с выбросами (21 точка)
6. Большой набор (50 точек)

Корректность проверяется:
- Размер выпуклой оболочки должен соответствовать ожидаемому
- Все точки в оболочке должны быть уникальными
- Результаты SEQ и MPI версий должны совпадать

**Тесты производительности:**

Вектор размером 10,000,000 точек генерируется случайным образом в диапазоне [-1000, 1000] для обеих координат.

## 7. Результаты и обсуждение

### 7.1. Корректность

Корректность реализации проверена следующими способами:

1. **Функциональные тесты:** Все 12 тестов пройдены успешно (6 тестов × 2 версии)
2. **Сравнение SEQ и MPI:** Результаты идентичны на всех тестовых данных
3. **Граничные случаи:** Протестированы наборы от 3 до 50 точек
4. **Специальные случаи:** Коллинеарные точки, внутренние точки, симметричные конфигурации

### 7.2. Производительность

Результаты измерений на векторе из 10,000,000 точек.

**task_run (только вычисления):**

| **Режим** | **Процессов** | **Время, с** | **Speedup** | **Efficiency** |
|-----------|---------------|--------------|-------------|----------------|
| SEQ       | 1             | 3.427        | 1.00        | N/A            |
| MPI       | 2             | 1.845        | 1.86        | 93%            |
| MPI       | 4             | 1.023        | 3.35        | 84%            |
| MPI       | 8             | 0.687        | 4.99        | 62%            |

**task_pipeline (полный конвейер с PreProcessing и PostProcessing):**

| **Режим** | **Процессов** | **Время, с** | **Speedup** | **Efficiency** |
|-----------|---------------|--------------|-------------|----------------|
| SEQ       | 1             | 3.512        | 1.00        | N/A            |
| MPI       | 2             | 1.958        | 1.79        | 90%            |
| MPI       | 4             | 1.145        | 3.07        | 77%            |
| MPI       | 8             | 0.823        | 4.27        | 53%            |

**Расчет показателей:**
- Ускорение (Speedup) = T_seq / T_mpi
- Эффективность (Efficiency) = (Speedup / P) × 100%

**Анализ результатов:**

1. **Режим task_run (только вычисления):**
   - На 2 процессах достигается почти линейное ускорение (1.86×) с эффективностью 93%
   - На 4 процессах ускорение 3.35× (эффективность 84%) - отличный результат
   - На 8 процессах ускорение 4.99× (эффективность 62%) - хорошее масштабирование

2. **Режим task_pipeline:**
   - На 2 процессах ускорение 1.79× (эффективность 90%) - накладные расходы на коммуникацию начинают проявляться
   - На 4 процессах ускорение 3.07× (эффективность 77%) - разница с task_run связана с временем на PreProcessing
   - На 8 процессах ускорение 4.27× (эффективность 53%) - коммуникационные затраты более заметны

3. **Сравнение режимов:**
   - Разница между task_run и task_pipeline показывает накладные расходы на распределение данных
   - При увеличении числа процессов эта разница растет из-за большего числа коммуникаций

4. **Масштабируемость:**
   - Алгоритм хорошо масштабируется до 4 процессов (эффективность > 77%)
   - На 8 процессах эффективность снижается, но остается приемлемой (53-62%)
   - Дальнейшее увеличение числа процессов нецелесообразно из-за роста коммуникационных затрат

## 8. Выводы

В ходе работы были получены следующие результаты:

1. **Реализация:** Разработаны и протестированы последовательная и параллельная версии алгоритма Грэхема для построения выпуклой оболочки

2. **Корректность:** Все функциональные тесты пройдены. SEQ и MPI версии дают идентичные результаты на всех тестовых данных

3. **Производительность:** На наборе из 10 млн точек достигнуто:
   - task_run режим: ускорение 4.99× на 8 процессах
   - task_pipeline режим: ускорение 4.27× на 8 процессах
   - Высокая эффективность на 2-4 процессах (77-93%)

4. **Масштабируемость:** Алгоритм показывает хорошую масштабируемость до 4 процессов, после чего эффективность снижается из-за коммуникационных затрат

5. **Практическая применимость:** Параллельная версия целесообразна для обработки больших наборов точек (>1 млн) на системах с 2-4 процессами

6. **Особенности:** Подход "разделяй и властвуй" с объединением локальных оболочек эффективен, но требует финального шага объединения на главном процессе

## 9. Список источников информации

1. Graham, R. L. "An Efficient Algorithm for Determining the Convex Hull of a Finite Planar Set". Information Processing Letters, 1972
2. MPI Forum. MPI: A Message-Passing Interface Standard, Version 4.0. 2021. https://www.mpi-forum.org/docs/
3. Cormen, T. H., Leiserson, C. E., Rivest, R. L., Stein, C. "Introduction to Algorithms", 3rd Edition. MIT Press, 2009
4. Сысоев А. В. Лекции по параллельному программированию. — Н. Новгород: ННГУ, 2025
